{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc f1 score in ltr setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()\n",
    "\n",
    "# Store the paths to files containing training and test instances.\n",
    "# As noted above, we will assume the data is in the LibSVM format\n",
    "# and that the content of each file is sorted by query ID.\n",
    "\n",
    "_TRAIN_DATA_PATH = ''\n",
    "_TEST_DATA_PATH = ''\n",
    "\n",
    "# Define a loss function. To find a complete list of available\n",
    "# loss functions or to learn how to add your own custom function\n",
    "# please refer to the tensorflow_ranking.losses module.\n",
    "_LOSS = \"pairwise_logistic_loss\"\n",
    "# _LOSS = \"sigmoid_cross_entropy_loss\"\n",
    "\n",
    "# In the TF-Ranking framework, a training instance is represented\n",
    "# by a Tensor that contains features from a list of documents\n",
    "# associated with a single query. For simplicity, we fix the shape\n",
    "# of these Tensors to a maximum list size and call it \"list_size,\"\n",
    "# the maximum number of documents per query in the dataset.\n",
    "# In this demo, we take the following approach:\n",
    "#   * If a query has fewer documents, its Tensor will be padded\n",
    "#     appropriately.\n",
    "#   * If a query has more documents, we shuffle its list of\n",
    "#     documents and trim the list down to the prescribed list_size.\n",
    "_LIST_SIZE = 12\n",
    "\n",
    "# The total number of features per query-document pair.\n",
    "# We set this number to the number of features in the MSLR-Web30K\n",
    "# dataset.\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 100\n",
    "_HIDDEN_LAYER_DIMS = [\"20\", \"10\"]\n",
    "\n",
    "\n",
    "# _OUT_DIR = \"../models/tfranking/\"\n",
    "\n",
    "def input_fn(path):\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
    "        output_types=(\n",
    "            {str(k): tf.float32 for k in range(1, _NUM_FEATURES + 1)},\n",
    "            tf.float32\n",
    "        ),\n",
    "        output_shapes=(\n",
    "            {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
    "             for k in range(1, _NUM_FEATURES + 1)},\n",
    "            tf.TensorShape([_LIST_SIZE])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    train_dataset = train_dataset.batch(_BATCH_SIZE)\n",
    "    return train_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    feature_names = [\n",
    "        \"%d\" % (i + 1) for i in range(0, _NUM_FEATURES)\n",
    "    ]\n",
    "    return {\n",
    "        name: tf.feature_column.numeric_column(\n",
    "            name, shape=(1,), default_value=0.0) for name in feature_names\n",
    "    }\n",
    "\n",
    "\n",
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a documents.\"\"\"\n",
    "        del params\n",
    "        del config\n",
    "        # Define input layer.\n",
    "        example_input = [\n",
    "            tf.layers.flatten(group_features[name])\n",
    "            for name in sorted(example_feature_columns())\n",
    "        ]\n",
    "        input_layer = tf.concat(example_input, 1)\n",
    "\n",
    "        cur_layer = input_layer\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.layers.dense(\n",
    "                cur_layer,\n",
    "                units=layer_width,\n",
    "                activation=\"tanh\")\n",
    "\n",
    "        logits = tf.layers.dense(cur_layer, units=1)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn\n",
    "\n",
    "\n",
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "\n",
    "    def _auc(labels, predictions, features):\n",
    "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "\n",
    "    Returns:\n",
    "    A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "    metric_fns.update({\n",
    "        \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [1, 3, 5, 10]\n",
    "    })\n",
    "\n",
    "    return metric_fns\n",
    "\n",
    "\n",
    "def get_estimator(hparams):\n",
    "    \"\"\"Create a ranking estimator.\n",
    "\n",
    "    Args:\n",
    "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
    "\n",
    "    Returns:\n",
    "    tf.learn `Estimator`.\n",
    "    \"\"\"\n",
    "\n",
    "    def _train_op_fn(loss):\n",
    "        \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "        return tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=hparams.learning_rate,\n",
    "            optimizer=\"Adagrad\")\n",
    "\n",
    "    ranking_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
    "        eval_metric_fns=eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=tfr.model.make_groupwise_ranking_fn(\n",
    "            group_score_fn=make_score_fn(),\n",
    "            group_size=1,\n",
    "            transform_fn=None,\n",
    "            ranking_head=ranking_head),\n",
    "        params=hparams)\n",
    "\n",
    "def create_f1_score(df, features, ranker, path):\n",
    "    '''\n",
    "    This function creates the f1 score. First we get the predictions on df and the file in path.\n",
    "    Then we look for the maximum of the predictions and choose these transport_modes\n",
    "    :param df: DataFrame where the file of path comes from\n",
    "    :param features: .txt feature list with all features to use\n",
    "    :param ranker: Trained model\n",
    "    :param path: Path to libsvm file\n",
    "    :return: DataFrame with right transport mode and yhat\n",
    "    '''\n",
    "\n",
    "    print('Start to create f1 score.')\n",
    "    # Add sid to the feature set to group by later\n",
    "    features = features + ['sid']\n",
    "\n",
    "    # Predict on trained ranker\n",
    "    preds = ranker.predict(input_fn=lambda: input_fn(path))\n",
    "\n",
    "    # Go through preds generator object and append all predictions to one list\n",
    "    print('Start predictions...')\n",
    "    li_preds = []\n",
    "    for i in preds:\n",
    "        li_preds.append(i)\n",
    "\n",
    "    # Create numpy array from list\n",
    "    li_preds = np.array(li_preds)\n",
    "\n",
    "    # df_all is an empty DataFrame to append all right f1 scores\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all unique sids to get DataFrame\n",
    "    # Iterate through number of unique sids to get yhats\n",
    "    print('Creating df_all DataFrame to get just first ranking')\n",
    "    for current_sid, nr_sid in zip(df.sid.unique(), range(0, df.sid.nunique())):\n",
    "        print('SID: ', current_sid)\n",
    "        curr_preds = li_preds[nr_sid]\n",
    "        df_one_sid = df[df.sid == current_sid]\n",
    "        df_one_sid = df_one_sid.assign(yhat=None)\n",
    "        for current_row in range(0, len(df_one_sid)):\n",
    "            df_one_sid.iloc[current_row, -1] = curr_preds[current_row]\n",
    "        df_all = df_all.append(df)\n",
    "\n",
    "\n",
    "    score = f1_score(df.groupby(\"sid\").first()['click_mode'], df_all.transport_mode, average='weighted')\n",
    "\n",
    "    print('F1 Score is: {}'.format(score))\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpbxwqkfsh\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpbxwqkfsh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faaa84bbe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpbxwqkfsh/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7905427, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpbxwqkfsh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7905427.\n",
      "Start to create f1 score.\n",
      "Start predictions...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpbxwqkfsh/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Creating df_all DataFrame to get just first ranking\n",
      "SID:  10\n",
      "SID:  21\n",
      "SID:  25\n",
      "SID:  34\n",
      "SID:  35\n",
      "SID:  36\n",
      "SID:  44\n",
      "SID:  68\n",
      "SID:  69\n",
      "SID:  79\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 520]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-74e00f05c810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TRAIN_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TEST_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-eeff229a60e5>\u001b[0m in \u001b[0;36mcreate_f1_score\u001b[0;34m(df, features, ranker, path)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click_mode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 Score is: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 520]"
     ]
    }
   ],
   "source": [
    "df_train_train = pd.read_pickle(\"../data/processed/ranking/train_all_row_sample_50.pickle\")\n",
    "df_train_test = pd.read_pickle(\"../data/processed/ranking/train_all_row_sample_50.pickle\")\n",
    "\n",
    "_TRAIN_DATA_PATH=\"../data/processed/ranking/train_all_row_sample_50.libsvm\"\n",
    "_TEST_DATA_PATH=\"../data/processed/ranking/train_all_row_sample_50.libsvm\"\n",
    "\n",
    "with open('../data/processed/ranking/features_tfranking.txt') as f:\n",
    "    features = f.read().splitlines()\n",
    "\n",
    "_NUM_FEATURES = len(features)\n",
    "\n",
    "hparams = tf.contrib.training.HParams(learning_rate=0.001)\n",
    "ranker = get_estimator(hparams)\n",
    "\n",
    "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=100)\n",
    "\n",
    "df_preds = create_f1_score(df_train_test, features, ranker, _TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sid to the feature set to group by later\n",
    "features = features + ['sid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predictions...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpbxwqkfsh/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "preds = ranker.predict(input_fn=lambda: input_fn(path))\n",
    "\n",
    "\n",
    "# Go through preds generator object and append all predictions to one list\n",
    "print('Start predictions...')\n",
    "li_preds = []\n",
    "for i in preds:\n",
    "    li_preds.append(i)\n",
    "\n",
    "# Create numpy array from list\n",
    "li_preds = np.array(li_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0477258e-01, -1.0477258e-01, -1.0477258e-01, -1.0477258e-01,\n",
       "         5.2324462e-01,  7.1415114e-01,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [-1.0477258e-01, -1.0477258e-01,  5.2324462e-01,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [-9.9973068e-02, -1.0477258e-01, -3.3014762e-01, -6.5889239e-01,\n",
       "         2.1583754e-01, -6.5889239e-01,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [-1.0477258e-01,  7.1415114e-01, -1.0477258e-01,  1.7805666e-02,\n",
       "        -1.0477258e-01,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [ 2.1583754e-01, -2.4755168e-01, -2.4755168e-01, -1.0477258e-01,\n",
       "         2.1583754e-01, -3.3014762e-01,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [-2.4755168e-01, -2.4755168e-01,  1.2087518e-01, -1.0477258e-01,\n",
       "        -3.3014762e-01,  2.1583754e-01,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [-1.0477258e-01,  5.2324462e-01,  7.1415114e-01,  5.2324462e-01,\n",
       "        -1.0477258e-01,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [ 5.2324462e-01, -1.0477258e-01, -1.0477258e-01, -1.0477258e-01,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [ 5.2324462e-01,  2.1583754e-01, -1.0477258e-01,  2.1583754e-01,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05],\n",
       "       [ 2.1583754e-01, -2.4755168e-01,  2.1583754e-01, -2.9748911e-01,\n",
       "         2.1583754e-01, -1.0477258e-01,  2.1583754e-01,  1.8639337e-05,\n",
       "         1.8639337e-05,  1.8639337e-05,  1.8639337e-05,  1.8639337e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating df_all DataFrame to get just first ranking\n",
      "SID:  10\n",
      "SID:  21\n",
      "SID:  25\n",
      "SID:  34\n",
      "SID:  35\n",
      "SID:  36\n",
      "SID:  44\n",
      "SID:  68\n",
      "SID:  69\n",
      "SID:  79\n"
     ]
    }
   ],
   "source": [
    "df = df_train_test.copy()\n",
    "# df_all is an empty DataFrame to append all right f1 scores\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "# Iterate through all unique sids to get DataFrame\n",
    "# Iterate through number of unique sids to get yhats\n",
    "print('Creating df_all DataFrame to get just first ranking')\n",
    "for current_sid, nr_sid in zip(df.sid.unique(), range(0, df.sid.nunique())):\n",
    "    print('SID: ', current_sid)\n",
    "    curr_preds = li_preds[nr_sid]\n",
    "    df_one_sid = df[df.sid == current_sid]\n",
    "    df_one_sid = df_one_sid.assign(yhat=None)\n",
    "    for current_row in range(0, len(df_one_sid)):\n",
    "        df_one_sid.iloc[current_row, -1] = curr_preds[current_row]\n",
    "    df_all = df_all.append(df_one_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values('yhat', ascending=False).drop_duplicates(['sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.groupby(\"sid\").first()['click_mode'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sid\n",
       "10    1\n",
       "21    2\n",
       "25    1\n",
       "34    9\n",
       "35    1\n",
       "36    1\n",
       "44    2\n",
       "68    2\n",
       "69    1\n",
       "79    2\n",
       "Name: click_mode, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"sid\").first()['click_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>transport_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432356</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435573</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460647</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440479</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449042</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440470</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448076</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456425</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455293</th>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459534</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid  transport_mode\n",
       "1432356   10               2\n",
       "1435573   21               3\n",
       "1460647   25               6\n",
       "1440479   34               2\n",
       "1449042   35               1\n",
       "1440470   36               4\n",
       "1448076   44               2\n",
       "1456425   68               1\n",
       "1455293   69               4\n",
       "1459534   79               2"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sort_values('sid')[['sid', 'transport_mode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = df_all.sort_values('sid')['transport_mode'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 9, 1, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 6, 2, 1, 4, 2, 1, 4, 2])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34285714285714286"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, yhat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(df.groupby(\"sid\").first()['click_mode'].values,\n",
    "                 df_all.sort_values('sid')['transport_mode'].values,\n",
    "                 average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltr_to_submission(df, features, ranker, path):\n",
    "    features = features + ['sid']\n",
    "\n",
    "    preds = ranker.predict(input_fn=lambda: input_fn(path))\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    # Not sure how to get all preds because it runs infinit\n",
    "    # So I take all till list size\n",
    "    preds_slice = itertools.islice(preds, len(df))\n",
    "    count = 0\n",
    "    a = np.zeros((len(df), _LIST_SIZE))\n",
    "\n",
    "    for i in preds_slice:\n",
    "        a[count] = i\n",
    "        count += 1\n",
    "\n",
    "    test_X = df[features]\n",
    "\n",
    "    test_X = test_X.assign(yhat=a[:, 0])\n",
    "\n",
    "    df_end = pd.DataFrame(columns=['yhat'], index=df.sid.unique())\n",
    "\n",
    "    df_end = test_X.sort_values(['sid', 'yhat'], ascending=False).groupby('sid').first()[[\n",
    "        'yhat', 'transport_mode'\n",
    "    ]]\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    score = f1_score(df.groupby(\"sid\").first()['click_mode'], df_end.transport_mode, average='weighted')\n",
    "    print('F1 Score is: {}'.format(score))\n",
    "\n",
    "    return df_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = _TEST_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ranker.predict(input_fn=lambda: input_fn(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object EstimatorV2.predict at 0x7faaa85a2318>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>click_time</th>\n",
       "      <th>click_mode</th>\n",
       "      <th>distance_plan</th>\n",
       "      <th>eta</th>\n",
       "      <th>price</th>\n",
       "      <th>transport_mode</th>\n",
       "      <th>plan_time_x</th>\n",
       "      <th>pid</th>\n",
       "      <th>req_time</th>\n",
       "      <th>...</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind</th>\n",
       "      <th>weather_dy</th>\n",
       "      <th>weather_dyq</th>\n",
       "      <th>weather_q</th>\n",
       "      <th>weather_qdy</th>\n",
       "      <th>weather_xq</th>\n",
       "      <th>weather_xydy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432355</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47429</td>\n",
       "      <td>4604</td>\n",
       "      <td>14100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432357</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47429</td>\n",
       "      <td>4604</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432360</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>48995</td>\n",
       "      <td>7396</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432359</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47796</td>\n",
       "      <td>7234</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432358</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>49758</td>\n",
       "      <td>6878</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432356</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>49067</td>\n",
       "      <td>6345</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435574</th>\n",
       "      <td>21</td>\n",
       "      <td>2018-11-10 12:16:36</td>\n",
       "      <td>2</td>\n",
       "      <td>7667</td>\n",
       "      <td>1229</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>177401.0</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435572</th>\n",
       "      <td>21</td>\n",
       "      <td>2018-11-10 12:16:36</td>\n",
       "      <td>2</td>\n",
       "      <td>6157</td>\n",
       "      <td>1289</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>177401.0</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435573</th>\n",
       "      <td>21</td>\n",
       "      <td>2018-11-10 12:16:36</td>\n",
       "      <td>2</td>\n",
       "      <td>7667</td>\n",
       "      <td>929</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>177401.0</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460646</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-11-10 23:51:30</td>\n",
       "      <td>1</td>\n",
       "      <td>2714</td>\n",
       "      <td>2434</td>\n",
       "      <td>700.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-11-10 23:51:25</td>\n",
       "      <td>176887.0</td>\n",
       "      <td>2018-11-10 23:51:25</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid           click_time  click_mode  distance_plan   eta    price  \\\n",
       "1432355   10  2018-11-10 11:13:24           1          47429  4604  14100.0   \n",
       "1432357   10  2018-11-10 11:13:24           1          47429  4604    700.0   \n",
       "1432360   10  2018-11-10 11:13:24           1          48995  7396   3200.0   \n",
       "1432359   10  2018-11-10 11:13:24           1          47796  7234   3000.0   \n",
       "1432358   10  2018-11-10 11:13:24           1          49758  6878   5500.0   \n",
       "1432356   10  2018-11-10 11:13:24           1          49067  6345   3100.0   \n",
       "1435574   21  2018-11-10 12:16:36           2           7667  1229   2100.0   \n",
       "1435572   21  2018-11-10 12:16:36           2           6157  1289    300.0   \n",
       "1435573   21  2018-11-10 12:16:36           2           7667   929    700.0   \n",
       "1460646   25  2018-11-10 23:51:30           1           2714  2434    700.0   \n",
       "\n",
       "         transport_mode          plan_time_x       pid            req_time  \\\n",
       "1432355               4  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432357               3  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432360               1  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432359              11  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432358               8  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432356               2  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1435574               4  2018-11-10 12:16:01  177401.0 2018-11-10 12:16:01   \n",
       "1435572               2  2018-11-10 12:16:01  177401.0 2018-11-10 12:16:01   \n",
       "1435573               3  2018-11-10 12:16:01  177401.0 2018-11-10 12:16:01   \n",
       "1460646               5  2018-11-10 23:51:25  176887.0 2018-11-10 23:51:25   \n",
       "\n",
       "         ...  max_temp  min_temp  weather  wind  weather_dy  weather_dyq  \\\n",
       "1432355  ...        11         0       dy    12           1            0   \n",
       "1432357  ...        11         0       dy    12           1            0   \n",
       "1432360  ...        11         0       dy    12           1            0   \n",
       "1432359  ...        11         0       dy    12           1            0   \n",
       "1432358  ...        11         0       dy    12           1            0   \n",
       "1432356  ...        11         0       dy    12           1            0   \n",
       "1435574  ...        11         0       dy    12           1            0   \n",
       "1435572  ...        11         0       dy    12           1            0   \n",
       "1435573  ...        11         0       dy    12           1            0   \n",
       "1460646  ...        11         0       dy    12           1            0   \n",
       "\n",
       "         weather_q weather_qdy  weather_xq  weather_xydy  \n",
       "1432355          0           0           0             0  \n",
       "1432357          0           0           0             0  \n",
       "1432360          0           0           0             0  \n",
       "1432359          0           0           0             0  \n",
       "1432358          0           0           0             0  \n",
       "1432356          0           0           0             0  \n",
       "1435574          0           0           0             0  \n",
       "1435572          0           0           0             0  \n",
       "1435573          0           0           0             0  \n",
       "1460646          0           0           0             0  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzksxnjev/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[-1.5062747e+00 -1.5062747e+00 -9.7568709e-01 -1.5062747e+00\n",
      " -1.5062747e+00 -1.5062747e+00 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.5062747e+00 -1.4046730e+00 -1.5062747e+00 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.4046730e+00 -1.1392306e+00 -8.3637077e-01 -1.1067839e+00\n",
      " -1.5062747e+00 -1.1392306e+00 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.5062747e+00 -1.5062747e+00 -1.5062747e+00 -6.2472087e-01\n",
      " -1.5062747e+00 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.4046730e+00 -1.4046730e+00 -1.4046730e+00 -1.4046730e+00\n",
      " -8.3637077e-01 -1.1067839e+00 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.4046730e+00 -6.2472087e-01 -8.3637077e-01 -1.1335293e+00\n",
      " -1.4046730e+00 -1.4046730e+00 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.5062747e+00 -1.5062747e+00 -1.5062747e+00 -1.5062747e+00\n",
      " -1.3344415e+00 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.5062747e+00 -1.5062747e+00 -1.5062747e+00 -1.5062747e+00\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.5062747e+00 -1.5062747e+00 -1.4046730e+00 -1.5062747e+00\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n",
      "[-1.4046730e+00 -1.4046730e+00 -1.4046730e+00 -6.2472087e-01\n",
      " -9.1678047e-01 -1.5062702e+00 -1.4046730e+00 -1.2835342e-04\n",
      " -1.2835342e-04 -1.2835342e-04 -1.2835342e-04 -1.2835342e-04]\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "for i in preds:\n",
    "    print(i)\n",
    "    a.append(i)\n",
    "    \n",
    "a = np.array(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preds are: \n",
    "* One prediction per row \n",
    "* One \"array\" entry per qid\n",
    "* Rest is padded\n",
    "* Not sure if min or max because the min in this case is the padded and max is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat yhat to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all with the same qid e.g. 10\n",
    "df = df_train_test[df_train_test.sid == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>click_time</th>\n",
       "      <th>click_mode</th>\n",
       "      <th>distance_plan</th>\n",
       "      <th>eta</th>\n",
       "      <th>price</th>\n",
       "      <th>transport_mode</th>\n",
       "      <th>plan_time_x</th>\n",
       "      <th>pid</th>\n",
       "      <th>req_time</th>\n",
       "      <th>...</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind</th>\n",
       "      <th>weather_dy</th>\n",
       "      <th>weather_dyq</th>\n",
       "      <th>weather_q</th>\n",
       "      <th>weather_qdy</th>\n",
       "      <th>weather_xq</th>\n",
       "      <th>weather_xydy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432355</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47429</td>\n",
       "      <td>4604</td>\n",
       "      <td>14100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432357</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47429</td>\n",
       "      <td>4604</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432360</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>48995</td>\n",
       "      <td>7396</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432359</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>47796</td>\n",
       "      <td>7234</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432358</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>49758</td>\n",
       "      <td>6878</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432356</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>49067</td>\n",
       "      <td>6345</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid           click_time  click_mode  distance_plan   eta    price  \\\n",
       "1432355   10  2018-11-10 11:13:24           1          47429  4604  14100.0   \n",
       "1432357   10  2018-11-10 11:13:24           1          47429  4604    700.0   \n",
       "1432360   10  2018-11-10 11:13:24           1          48995  7396   3200.0   \n",
       "1432359   10  2018-11-10 11:13:24           1          47796  7234   3000.0   \n",
       "1432358   10  2018-11-10 11:13:24           1          49758  6878   5500.0   \n",
       "1432356   10  2018-11-10 11:13:24           1          49067  6345   3100.0   \n",
       "\n",
       "         transport_mode          plan_time_x       pid            req_time  \\\n",
       "1432355               4  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432357               3  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432360               1  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432359              11  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432358               8  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1432356               2  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "\n",
       "         ...  max_temp  min_temp  weather  wind  weather_dy  weather_dyq  \\\n",
       "1432355  ...        11         0       dy    12           1            0   \n",
       "1432357  ...        11         0       dy    12           1            0   \n",
       "1432360  ...        11         0       dy    12           1            0   \n",
       "1432359  ...        11         0       dy    12           1            0   \n",
       "1432358  ...        11         0       dy    12           1            0   \n",
       "1432356  ...        11         0       dy    12           1            0   \n",
       "\n",
       "         weather_q weather_qdy  weather_xq  weather_xydy  \n",
       "1432355          0           0           0             0  \n",
       "1432357          0           0           0             0  \n",
       "1432360          0           0           0             0  \n",
       "1432359          0           0           0             0  \n",
       "1432358          0           0           0             0  \n",
       "1432356          0           0           0             0  \n",
       "\n",
       "[6 rows x 98 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(yhat = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID: 10\n",
      "Length of df: 6\n",
      "SID: 21\n",
      "Length of df: 3\n",
      "SID: 25\n",
      "Length of df: 6\n",
      "SID: 34\n",
      "Length of df: 5\n",
      "SID: 35\n",
      "Length of df: 6\n",
      "SID: 36\n",
      "Length of df: 6\n",
      "SID: 44\n",
      "Length of df: 5\n",
      "SID: 68\n",
      "Length of df: 4\n",
      "SID: 69\n",
      "Length of df: 4\n",
      "SID: 79\n",
      "Length of df: 7\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "# Iterate through all unique sids to get DataFrame\n",
    "# Iterate through number of unique sids to get yhats\n",
    "for current_sid, nr_sid in zip(df_train_test.sid.unique(), range(0,df_train_test.sid.nunique())):\n",
    "    print('SID: {}'.format(current_sid))\n",
    "    curr_preds = a[nr_sid]\n",
    "    df = df_train_test[df_train_test.sid == current_sid]\n",
    "    print('Length of df: {}'.format(len(df)))\n",
    "    df = df.assign(yhat=None)\n",
    "    for current_row in range(0, len(df)):\n",
    "        df.iloc[current_row, -1] = curr_preds[current_row]\n",
    "    df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>click_time</th>\n",
       "      <th>click_mode</th>\n",
       "      <th>distance_plan</th>\n",
       "      <th>eta</th>\n",
       "      <th>price</th>\n",
       "      <th>transport_mode</th>\n",
       "      <th>plan_time_x</th>\n",
       "      <th>pid</th>\n",
       "      <th>req_time</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind</th>\n",
       "      <th>weather_dy</th>\n",
       "      <th>weather_dyq</th>\n",
       "      <th>weather_q</th>\n",
       "      <th>weather_qdy</th>\n",
       "      <th>weather_xq</th>\n",
       "      <th>weather_xydy</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440474</th>\n",
       "      <td>36</td>\n",
       "      <td>2018-11-10 13:43:03</td>\n",
       "      <td>1</td>\n",
       "      <td>3453</td>\n",
       "      <td>1801</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 13:42:49</td>\n",
       "      <td>106441.0</td>\n",
       "      <td>2018-11-10 13:42:49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.624721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440480</th>\n",
       "      <td>34</td>\n",
       "      <td>2018-11-10 13:43:19</td>\n",
       "      <td>9</td>\n",
       "      <td>24642</td>\n",
       "      <td>3530</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-10 13:42:54</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-11-10 13:42:54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.624721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459537</th>\n",
       "      <td>79</td>\n",
       "      <td>2018-11-10 22:09:48</td>\n",
       "      <td>2</td>\n",
       "      <td>3479</td>\n",
       "      <td>3210</td>\n",
       "      <td>700.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-11-10 22:09:43</td>\n",
       "      <td>148770.0</td>\n",
       "      <td>2018-11-10 22:09:43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.624721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460648</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-11-10 23:51:30</td>\n",
       "      <td>1</td>\n",
       "      <td>3006</td>\n",
       "      <td>2419</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 23:51:25</td>\n",
       "      <td>176887.0</td>\n",
       "      <td>2018-11-10 23:51:25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.836371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449042</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-11-10 16:37:25</td>\n",
       "      <td>1</td>\n",
       "      <td>4008</td>\n",
       "      <td>2176</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 16:37:17</td>\n",
       "      <td>106441.0</td>\n",
       "      <td>2018-11-10 16:37:17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.836371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432360</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-11-10 11:13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>48995</td>\n",
       "      <td>7396</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>199899.0</td>\n",
       "      <td>2018-11-10 11:10:36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.975687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448074</th>\n",
       "      <td>44</td>\n",
       "      <td>2018-11-10 16:17:59</td>\n",
       "      <td>2</td>\n",
       "      <td>16983</td>\n",
       "      <td>2439</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-10 16:17:52</td>\n",
       "      <td>140368.0</td>\n",
       "      <td>2018-11-10 16:17:52</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.334442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455295</th>\n",
       "      <td>69</td>\n",
       "      <td>2018-11-10 18:55:34</td>\n",
       "      <td>1</td>\n",
       "      <td>10489</td>\n",
       "      <td>2955</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-10 18:55:23</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-11-10 18:55:23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.404673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435572</th>\n",
       "      <td>21</td>\n",
       "      <td>2018-11-10 12:16:36</td>\n",
       "      <td>2</td>\n",
       "      <td>6157</td>\n",
       "      <td>1289</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>177401.0</td>\n",
       "      <td>2018-11-10 12:16:01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.404673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456423</th>\n",
       "      <td>68</td>\n",
       "      <td>2018-11-10 19:38:08</td>\n",
       "      <td>2</td>\n",
       "      <td>9977</td>\n",
       "      <td>1014</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-10 19:38:01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-11-10 19:38:01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.506275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sid           click_time  click_mode  distance_plan   eta   price  \\\n",
       "1440474   36  2018-11-10 13:43:03           1           3453  1801   200.0   \n",
       "1440480   34  2018-11-10 13:43:19           9          24642  3530  9200.0   \n",
       "1459537   79  2018-11-10 22:09:48           2           3479  3210   700.0   \n",
       "1460648   25  2018-11-10 23:51:30           1           3006  2419   200.0   \n",
       "1449042   35  2018-11-10 16:37:25           1           4008  2176   200.0   \n",
       "1432360   10  2018-11-10 11:13:24           1          48995  7396  3200.0   \n",
       "1448074   44  2018-11-10 16:17:59           2          16983  2439  4700.0   \n",
       "1455295   69  2018-11-10 18:55:34           1          10489  2955   200.0   \n",
       "1435572   21  2018-11-10 12:16:36           2           6157  1289   300.0   \n",
       "1456423   68  2018-11-10 19:38:08           2           9977  1014   700.0   \n",
       "\n",
       "         transport_mode          plan_time_x       pid            req_time  \\\n",
       "1440474               1  2018-11-10 13:42:49  106441.0 2018-11-10 13:42:49   \n",
       "1440480               4  2018-11-10 13:42:54      -1.0 2018-11-10 13:42:54   \n",
       "1459537               5  2018-11-10 22:09:43  148770.0 2018-11-10 22:09:43   \n",
       "1460648               1  2018-11-10 23:51:25  176887.0 2018-11-10 23:51:25   \n",
       "1449042               1  2018-11-10 16:37:17  106441.0 2018-11-10 16:37:17   \n",
       "1432360               1  2018-11-10 11:10:36  199899.0 2018-11-10 11:10:36   \n",
       "1448074               4  2018-11-10 16:17:52  140368.0 2018-11-10 16:17:52   \n",
       "1455295               1  2018-11-10 18:55:23      -1.0 2018-11-10 18:55:23   \n",
       "1435572               2  2018-11-10 12:16:01  177401.0 2018-11-10 12:16:01   \n",
       "1456423               3  2018-11-10 19:38:01      -1.0 2018-11-10 19:38:01   \n",
       "\n",
       "         ...  min_temp  weather  wind  weather_dy  weather_dyq  weather_q  \\\n",
       "1440474  ...         0       dy    12           1            0          0   \n",
       "1440480  ...         0       dy    12           1            0          0   \n",
       "1459537  ...         0       dy    12           1            0          0   \n",
       "1460648  ...         0       dy    12           1            0          0   \n",
       "1449042  ...         0       dy    12           1            0          0   \n",
       "1432360  ...         0       dy    12           1            0          0   \n",
       "1448074  ...         0       dy    12           1            0          0   \n",
       "1455295  ...         0       dy    12           1            0          0   \n",
       "1435572  ...         0       dy    12           1            0          0   \n",
       "1456423  ...         0       dy    12           1            0          0   \n",
       "\n",
       "         weather_qdy weather_xq  weather_xydy      yhat  \n",
       "1440474            0          0             0 -0.624721  \n",
       "1440480            0          0             0 -0.624721  \n",
       "1459537            0          0             0 -0.624721  \n",
       "1460648            0          0             0 -0.836371  \n",
       "1449042            0          0             0 -0.836371  \n",
       "1432360            0          0             0 -0.975687  \n",
       "1448074            0          0             0 -1.334442  \n",
       "1455295            0          0             0 -1.404673  \n",
       "1435572            0          0             0 -1.404673  \n",
       "1456423            0          0             0 -1.506275  \n",
       "\n",
       "[10 rows x 99 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by yhat and drop duplicates -> All right preds\n",
    "df_all.sort_values('yhat', ascending=False).drop_duplicates(['sid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
