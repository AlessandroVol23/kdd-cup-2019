{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import pandas as pd\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()\n",
    "\n",
    "# Store the paths to files containing training and test instances.\n",
    "# As noted above, we will assume the data is in the LibSVM format\n",
    "# and that the content of each file is sorted by query ID.\n",
    "\n",
    "_TRAIN_DATA_PATH = ''\n",
    "_TEST_DATA_PATH = ''\n",
    "\n",
    "# Define a loss function. To find a complete list of available\n",
    "# loss functions or to learn how to add your own custom function\n",
    "# please refer to the tensorflow_ranking.losses module.\n",
    "_LOSS = \"pairwise_logistic_loss\"\n",
    "# _LOSS = \"sigmoid_cross_entropy_loss\"\n",
    "\n",
    "# In the TF-Ranking framework, a training instance is represented\n",
    "# by a Tensor that contains features from a list of documents\n",
    "# associated with a single query. For simplicity, we fix the shape\n",
    "# of these Tensors to a maximum list size and call it \"list_size,\"\n",
    "# the maximum number of documents per query in the dataset.\n",
    "# In this demo, we take the following approach:\n",
    "#   * If a query has fewer documents, its Tensor will be padded\n",
    "#     appropriately.\n",
    "#   * If a query has more documents, we shuffle its list of\n",
    "#     documents and trim the list down to the prescribed list_size.\n",
    "_LIST_SIZE = 100\n",
    "\n",
    "# The total number of features per query-document pair.\n",
    "# We set this number to the number of features in the MSLR-Web30K\n",
    "# dataset.\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 1000\n",
    "_HIDDEN_LAYER_DIMS = [\"20\", \"10\"]\n",
    "\n",
    "\n",
    "# _OUT_DIR = \"../models/tfranking/\"\n",
    "\n",
    "def input_fn(path):\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
    "        output_types=(\n",
    "            {str(k): tf.float32 for k in range(1, _NUM_FEATURES + 1)},\n",
    "            tf.float32\n",
    "        ),\n",
    "        output_shapes=(\n",
    "            {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
    "             for k in range(1, _NUM_FEATURES + 1)},\n",
    "            tf.TensorShape([_LIST_SIZE])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(1000).repeat().batch(_BATCH_SIZE)\n",
    "    return train_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    feature_names = [\n",
    "        \"%d\" % (i + 1) for i in range(0, _NUM_FEATURES)\n",
    "    ]\n",
    "    return {\n",
    "        name: tf.feature_column.numeric_column(\n",
    "            name, shape=(1,), default_value=0.0) for name in feature_names\n",
    "    }\n",
    "\n",
    "\n",
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a documents.\"\"\"\n",
    "        del params\n",
    "        del config\n",
    "        # Define input layer.\n",
    "        example_input = [\n",
    "            tf.layers.flatten(group_features[name])\n",
    "            for name in sorted(example_feature_columns())\n",
    "        ]\n",
    "        input_layer = tf.concat(example_input, 1)\n",
    "\n",
    "        cur_layer = input_layer\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.layers.dense(\n",
    "                cur_layer,\n",
    "                units=layer_width,\n",
    "                activation=\"tanh\")\n",
    "\n",
    "        logits = tf.layers.dense(cur_layer, units=1)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn\n",
    "\n",
    "\n",
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "\n",
    "    def _auc(labels, predictions, features):\n",
    "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "\n",
    "    Returns:\n",
    "    A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "    metric_fns.update({\n",
    "        \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [1, 3, 5, 10]\n",
    "    })\n",
    "\n",
    "    return metric_fns\n",
    "\n",
    "\n",
    "def get_estimator(hparams):\n",
    "    \"\"\"Create a ranking estimator.\n",
    "\n",
    "    Args:\n",
    "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
    "\n",
    "    Returns:\n",
    "    tf.learn `Estimator`.\n",
    "    \"\"\"\n",
    "\n",
    "    def _train_op_fn(loss):\n",
    "        \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "        return tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=hparams.learning_rate,\n",
    "            optimizer=\"Adagrad\")\n",
    "\n",
    "    ranking_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
    "        eval_metric_fns=eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=tfr.model.make_groupwise_ranking_fn(\n",
    "            group_score_fn=make_score_fn(),\n",
    "            group_size=1,\n",
    "            transform_fn=None,\n",
    "            ranking_head=ranking_head),\n",
    "        params=hparams)\n",
    "\n",
    "\n",
    "def ltr_to_submission(df, features, ranker, path):\n",
    "    features = features + ['sid']\n",
    "\n",
    "    preds = ranker.predict(input_fn=lambda: input_fn(path))\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    # Not sure how to get all preds because it runs infinit\n",
    "    # So I take all till list size\n",
    "    preds_slice = itertools.islice(preds, len(df))\n",
    "    count = 0\n",
    "    a = np.zeros((len(df), _LIST_SIZE))\n",
    "\n",
    "    for i in preds_slice:\n",
    "        a[count] = i\n",
    "        count += 1\n",
    "\n",
    "    test_X = df[features]\n",
    "\n",
    "    # Assign prediction vals to df\n",
    "    # Tried with a or a sum for all features\n",
    "    # a = a[:,0:_NUM_FEATURES]\n",
    "    # a = a.sum(axis=1)\n",
    "\n",
    "    test_X = test_X.assign(yhat=a[:, 0])\n",
    "\n",
    "    df_end = pd.DataFrame(columns=['yhat'], index=df.sid.unique())\n",
    "\n",
    "    df_end = test_X.sort_values(['sid', 'yhat'], ascending=False).groupby('sid').first()[[\n",
    "        'yhat', 'transport_mode'\n",
    "    ]]\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    score = f1_score(df.groupby(\"sid\").first()['click_mode'], df_end.transport_mode, average='weighted')\n",
    "    print('F1 Score is: {}'.format(score))\n",
    "\n",
    "    return df_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_hpc98z3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_hpc98z3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f819aa298d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "WARNING:tensorflow:From <ipython-input-13-5dcf8eb9a660>:50: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/tensorflow_ranking/python/model.py:268: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_hpc98z3/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/tmp_hpc98z3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_hpc98z3/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "F1 Score is: 0.18365367965367965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandro/anaconda3/envs/tf_ranking/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "df_train_train = pd.read_pickle(\"../data/processed/ranking/train_all_row_sample_50.pickle\")\n",
    "df_train_test = pd.read_pickle(\"../data/processed/ranking/train_all_row_sample_50.pickle\")\n",
    "\n",
    "_TRAIN_DATA_PATH=\"../data/processed/ranking/train_all_row_sample_50.libsvm\"\n",
    "_TEST_DATA_PATH=\"../data/processed/ranking/train_all_row_sample_50.libsvm\"\n",
    "\n",
    "with open('../data/processed/ranking/features_tfranking.txt') as f:\n",
    "    features = f.read().splitlines()\n",
    "\n",
    "_NUM_FEATURES = len(features)\n",
    "\n",
    "hparams = tf.contrib.training.HParams(learning_rate=0.05)\n",
    "ranker = get_estimator(hparams)\n",
    "\n",
    "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=10)\n",
    "\n",
    "df_preds = ltr_to_submission(df_train_test, features, ranker, _TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_hpc98z3/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "df = df_train_test.copy()\n",
    "preds = ranker.predict(input_fn=lambda: input_fn(_TEST_DATA_PATH))\n",
    "import itertools\n",
    "import numpy as np\n",
    "# Not sure how to get all preds because it runs infinit\n",
    "# So I take all till list size\n",
    "preds_slice = itertools.islice(preds, len(df))\n",
    "count = 0\n",
    "a = np.zeros((len(df), _LIST_SIZE))\n",
    "\n",
    "for i in preds_slice:\n",
    "    a[count] = i\n",
    "    count += 1\n",
    "\n",
    "test_X = df[features]\n",
    "\n",
    "# Assign prediction vals to df\n",
    "# Tried with a or a sum for all features\n",
    "# a = a[:,0:_NUM_FEATURES]\n",
    "# a = a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.22621489,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.28696692,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.18626857,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.28696692,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.04443657,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.34943655,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.29094639,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.68208516,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
